import requests
import json
import tweepy  
import sqlite3
import csv
import os 
import matplotlib
import matplotlib.pyplot as plt
import numpy as np

# Fill these in in the twitter_info.py file
consumer_key =  "51KkHDO8Ewqr6lIo5yQEP83Ro"
consumer_secret = "aJhvU5Zxs76phrk2yfm8XaznefTJpmot1s6kakR8FhxWi6uzXn"
access_token = "1445359550-vvfBG1xSFNz8bLw7zx36CkbZvN2Mh6UqyohDQT7"
access_token_secret = "NlAwhaKRyTc7P0O75cWn7gBcQQTLCcx4Pk4DyfFu1Kokk"
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)

def get_tweets(consumer_key,consumer_secret,access_token_secret,access_token, query): #already rate limited to 20
    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
    auth.set_access_token(access_token, access_token_secret)

    # Set up library to grab stuff from twitter with your authentication, and return it in a JSON format 
    api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())

    # a search example 
    results = api.search(q=query)
    contents= json.dumps(results)
    return results

def extract_info(results): 
    data=[]
    for status in results['statuses']:
        tweet= status["text"]
        print(tweet)
        name= status['user']['name']
        username=status['user']["screen_name"]
        location=status['user']['location']
        followers=status['user']['followers_count']
        mutuals=status['user']['friends_count']
        when= status['created_at']
        tweet_id=status['id']
        coords=status['coordinates']
        geo=status['geo']
        d={'id':tweet_id,"followers":followers, "tweet": tweet}
        # output
        data.append(d)
    return data 

def create_twitter_db():
    conn=sqlite3.connect('/Users/Lauren/Desktop/FinalProject/Twitter.db')
    twitter=conn.cursor() 
    twitter.execute('DROP TABLE IF EXISTS Tweets')
    twitter.execute('CREATE TABLE Tweets (Id INTEGER, Tweet TEXT)')
    twitter.execute('CREATE TABLE Followers (Id INTEGER, Followers INTEGER)')

def write_to_twitter_db(data, num=15): #num is what will restrict how much is written at a time
    conn=sqlite3.connect('/Users/Lauren/Desktop/FinalProject/Twitter.db')
    twitter=conn.cursor() 
    for i in range(0,num): #rate limited
        info=data[i]
        tweet_id=info['id']
        followers=info['followers']
        tweet=info['tweet']
        twitter.execute('INSERT INTO Tweets (Id, Tweet) VALUES (?, ?)',(tweet_id, tweet))
        twitter.execute('INSERT INTO Followers (Id, Followers) VALUES (?, ?)', (tweet_id, followers))
    conn.commit()

#NEED TO FIGURE OUT HOW TO AVOID DUPLICATES 

def retrieve_tweets_from_db():
    conn=sqlite3.connect('/Users/Lauren/Desktop/FinalProject/Twitter.db')
    twitter=conn.cursor() 
    twitter.execute('SELECT Tweets.Id, Tweets.Tweet, Followers.Followers from Tweets INNER JOIN Followers ON Tweets.Id =Followers.Id')
    #twitter.execute('SELECT * from Tweets')
    tweets=[]
    for row in twitter:
        tweets.append(row)
    twitter.close()
    return tweets

def get_sentiment_words():
    filename="sentiment_words.csv"
    root_path = os.path.dirname(os.path.abspath(__file__)) + '/' + filename
    file_obj=open(root_path, 'r')
    file_data = file_obj.readlines()

    sentiment={}
    for line in file_data[1:len(file_data)]:
        parts=line.split(",")
        combined=parts[0]
        score=(parts[1])
        both=combined.split('#')
        part_of_speech=both[1]
        word=both[0]
        score= score.strip('\n')
        score=float(score)
        sentiment[word]=score
    return sentiment

def analyze_twitter():  
    data=retrieve_tweets_from_db()
    sentiment=get_sentiment_words()
    results=[]
    for tup in data:
        Id=tup[0]
        text=tup[1]
        followers=tup[2]
        total=0
        for word in text.split():  #turning tweet into words
            if len(word)>20:      #not taking into account words longer than 20 words
                pass
            else:
                if word in sentiment:  #only taking words in the dictionary
                    total+= sentiment[word]  #summing, NOT averaging 
        info=(total, followers)
        results.append(info)
    return results

def get_top_words():
    data=retrieve_tweets_from_db()
    sentiment=get_sentiment_words()
    words={}
    for tup in data:
        text=tup[1]
        followers=tup[2]
        for word in text.split():  #turning tweet into words
            if len(word)>20:      #not taking into account words longer than 20 words
                pass
            else:
                if word in sentiment:  #only taking words in the dictionary
                    if word in words:
                        words[word]['frequency']+=1
                    else:
                        words[word]= {'score':sentiment[word], 'frequency':1}
    data_list=[]
    for word in list(words.keys()):
        score=words[word]['score']
        freq= words[word]['frequency']
        data_list.append((word, score, freq))
    return data_list

def plot_twitter_bar():
    data=get_top_words()
    top=sorted(data, key=lambda x: x[2], reverse=True)
    top3=top[0:3]
    words=[]
    scores=[]
    freqs=[]
    for word in top3:
        words.append(word[0])
        scores.append(word[1])
        freqs.append(word[2])
    plt.figure(1, figsize= (9, 3))
    plt.tight_layout()
    plt.axes(xlabel ='Word', ylabel="Frequency")
    plt.bar([1,2,3], freqs, color= ["pink", "gold", "deepskyblue"], tick_label=words)
    plt.suptitle('Most Frequent Word & Their Sentiment Score')    
    for i in range(1,4):
            plt.text(i-.1, 1, scores[i-1] )
    plt.show()
    plt.xticks(rotation=90) 
    

    pass

#COULD CREATE A WORD CLOUD HERE

#writes the contents to a file
def write_to_file(data, filename):
    f = open(filename, "w")
    f.write(json.dumps(data))
    f.close()
    print('The data you have just saved to {} is:'.format(filename))
    print(data)


def main():
    #get all SCHOOL RESULTS
    #MUST SPECIFICY ROUND 
    create_twitter_db()
    #print list of schools
    #while True:
    query=input("Please enter a school from the list above:     ")
    #if query in school results:
    #   break
    #else:
    #   print "School not in school list, please make sure to type it exactly as it is shown in the school results"

    for i in range(0,5):
        data= get_tweets(consumer_key,consumer_secret,access_token_secret,access_token, query)
        write_to_twitter_db(data)


def test():
    query=input("Please enter a school from the list above:     ")
    results=get_tweets(consumer_key,consumer_secret,access_token_secret,access_token, query)
    data=(extract_info(results))
    print(len(data))
    write_to_twitter_db(data)


#create_twitter_db()
#test()

#print(get_tweets(consumer_key,consumer_secret,access_token_secret,access_token, "University of Michigan"))

plot_twitter_bar()
